<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
	<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
	<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css" />
	<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet" />

	<title>Qingpeng Cai</title>
</head>

<body>
	<div id="wrap">

		<div id="toptitle">
			<h1>Qingpeng Cai (蔡庆芃)</h1>


		</div>
		<div id="separator"></div>

		<table class="imgtable"><tr><td>
			<img src="photos/qingpengcai.png" alt="" width="200px" height="230px" />&nbsp;</td>
			<td align="left"><p><br /> <br />
			<br />
			</p>
		</td></tr></table>


		<p>
			I am a Senior Staff Algorithm Engineer(资深算法专家) in KuaiShou Technology. I am responsible for business optimization and technical management.
			My core research interest is reinforcement learning, large language models, and recommendation.
			I lead the application of reinforcement learning to recommendation and advertising<a href=https://github.com/ksRecoTech/Wonderful-RL4Rec/tree/main>(papers and codebase)</a>.<br/><br/>

		More information can be found in <a href=https://scholar.google.com/citations?user=uU6s1tYAAAAJ&hl=en>Google Scholar</a>, <a href=https://dblp.org/pid/183/0940-1.html>DBLP.</a><br/><br/>

		I am hiring students passionate about RL and LLM. If interested, please feel free to contact me. Email:cqpcurry [@] gmail [DOT] com
	

			<h2>Selected Awards</h2>
		<ul>
			
			<li><p>First Prize of the General track at the <a href="https://tianchi.aliyun.com/competition/entrance/532236/rankingList">NeurIPS 2024 Competition: Auto-Bidding in Large-Scale Auctions</a> <a href="https://mp.weixin.qq.com/s/H2hrUEFVEm1uvsIBCNCe7g">[News Link]</a> </p></li>

			<li><p>First Prize of the AIGB track at the <a href="https://tianchi.aliyun.com/competition/entrance/532236/rankingList">NeurIPS 2024 Competition: Auto-Bidding in Large-Scale Auctions</a> <a href="https://mp.weixin.qq.com/s/H2hrUEFVEm1uvsIBCNCe7g">[News Link]</a> </p></li>

			<li><p>2024年“钱伟长中文信息处理科学技术奖”自然科学类一等奖<a href="https://www.cipsc.org.cn/InstituteNews/info_itemid_4753.html">[News Link]</a></p></li>

		</ul>
	
		<h2>Selected Invited Talks</h2>
		<ul>
			
			<li><p>
			<b> Reinforcement Learning for Short Video Recommender Systems</b>
                        <a href="https://videorecsys.com/slides/qingpeng_talk4.pdf">[pdf]</a><br/>
			The 1st Workshop on
LARGE-SCALE VIDEO RECOMMENDER SYSTEMS@ACM RecSys'23<br/>
			</p></li>


			<li><p>
			<b> Reinforcement Learning for Industrial Recommender Systems</b>
                        <a href="./pdfs/drl4ir.pdf">[pdf]</a><br/>
			DRL4IR@SIGIR2022<br/>
			</p></li>

		</ul>
	
		<h2>Professional Activities</h2>



		<li><b>Organizer:</b> <br/>
				<ul>
			<li><p><a href="https://agentirworkshop.github.io/about">Agent-based Information Retrieval Workshop </a>@SIGIR 2024, SIGIR 2025
						</p></li>
			</ul>


			<li><b>Area Chair:</b> <br/>
				<ul>
			<li><p>NeurIPS
						</p></li>
			</ul>

			<li><b>Senior Program Committee:</b> <br/>
				<ul>
			<li><p>AAMAS, CIKM
						</p></li>
			</ul>

			<li><b>Program Committee:</b> <br/>
				<ul>
			<li><p>TMLR, ICLR, ICML, KDD, WWW, IJCAI, AAAI 
						</p></li>
			</ul>
			


		<h2>Publications(* indicates the corresponding author)</h2>

		<li><b>LLM</b> <br/>


			<ul>
		<li><p>
			<b>LLM-Powered Efficient User Simulator for Recommender System</b>
			<a href=https://arxiv.org/pdf/2412.16984>[pdf]</a><br/>
			Zijian Zhang, Shuchang Liu, Ziru Liu, Rui Zhong, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Chunxu Zhang, Qidong Liu, Peng Jiang<br/>
			AAAI-2025, Oral <br/>
				</p></li>
		</ul>

		<ul>
		<li><p>
			<b>DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems</b><br/>
			<a href=https://arxiv.org/pdf/2408.12470>[pdf]</a><br/>
			Jiaju Chen, Chongming Gao, Shuai Yuan, Shuchang Liu,  <b>Qingpeng Cai</b>, Peng Jiang<br/>
			WSDM-2025 <br/>
			</p></li>
		</ul>

		<li><b>Reinforcement Learning</b> <br/>

		
		<ul>
			<li><p>
			<b>Flow Factorization for Efficient Generative Flow Networks</b>
			<a href=https://arxiv.org/pdf/2406.01901>[pdf]</a><br/>
			Jiashun Liu, Chunhui Li, Cheng-Hao Liu, Dianbo Liu, <b>Qingpeng Cai</b>, Ling Pan<br/>
			AAAI-2025, Oral <br/>
			</p></li>
		</ul>

	
		




							<ul>
		<li><p>
			<b>State Regularized Policy Optimization on Data with Dynamics Shift</b>
			<a href=https://arxiv.org/abs/2306.03552>[pdf]</a><br/>
			Zhenghai Xue,  <b>Qingpeng Cai</b>, Shuchang Liu, Dong Zheng, Peng Jiang, Kun Gai, Bo An<br/>
			NeurIPS-2023 <br/>
			</p></li>
		</ul>


		<ul>
			<li><p>
			<b>Exploration in policy optimization through multiple paths</b><br/> 
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			JAAMAS-2021<br/>
			</p></li>
		</ul>


				<ul>
			<li><p>
			<b>Softmax Deep Double Deterministic Policy Gradients</b>
			<a href=https://proceedings.neurips.cc/paper/2020/file/884d247c6f65a96a7da4d1105d584ddd-Paper.pdf>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			NeurIPS-2020 <br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Reinforcement Learning with Dynamic Boltzmann Softmax Updates</b>
			<a href=https://www.ijcai.org/proceedings/2020/0276.pdf>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Qi Meng, Wei Chen, Longbo Huang<br/>
			IJCAI-2020<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Multi-path Policy Optimization</b>
			<a href=https://arxiv.org/abs/1911.04207>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			AAMAS-2020<br/>
			<font color="Blue">(Invited for fast-track publication in JAAMAS, top 5%)</font><br/>
			</p></li>
		</ul>

		<ul>
			
			<li><p>
			<b>Deterministic Value-Policy Gradients</b>
			<a href=https://arxiv.org/abs/1909.03939>[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Ling Pan, Pingzhong Tang<br/>
			AAAI-2020<br/>
			</p></li>
		</ul>



					<ul>
			<li><p>
				<b>Policy optimization with model-based explorations</b><br/>
Feiyang Pan, <b>Qingpeng Cai</b>, An-Xiang Zeng, Chun-Xiang Pan, Qing Da, Hualin He, Qing He, Pingzhong Tang<br/>
				AAAI-2019<br/>
			</p></li>
		</ul>

					<ul>
			<li><p>
				<b>A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems</b> 
				<a href=https://arxiv.org/pdf/1802.04592.pdf>[pdf]</a><br/>
				Ling Pan, <b>Qingpeng Cai</b>, Zhixuan Fang, Pingzhong Tang, Longbo Huang<br/>
				AAAI-2019<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
				<b>Reinforcement Learning Driven Heuristic Optimization</b>
				<a href=https://arxiv.org/abs/1906.06639>[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Will Hang, Azalia Mirhoseini, George Tucker, Jingtao Wang, Wei Wei<br/>
				DRL4KDD-2019<br/>
			</p></li>			
		</ul>





		<ul>
			<li><p>
				<b>Policy gradients for contextual recommendations</b><br/>
				Feiyang Pan, <b>Qingpeng Cai</b>, Pingzhong Tang, Fuzhen Zhuang, Qing He<br/>
				WWW-2019<br/>
			</p></li>
		</ul>

</li>



		<li><b>Recommender Systems and Computational Advertising</b>  <br/>

		<ul>
			<li><p>
			<b>Generative Auto-Bidding with Value-Guided Explorations</b><br/>
			Jingtong Gao, Yewen Li, Shuai Mao, Peng Jiang, Nan Jiang, Yejing Wang,  <b>Qingpeng Cai*</b>, Fei Pan, Peng Jiang, Kun Gai, Bo An, Xiangyu Zhao<br/>
			SIGIR 2025, Full Paper<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
			<b>GAS: Generative Auto-bidding with Post-training Search</b>
			<a href=https://arxiv.org/pdf/2412.17018>[pdf]</a><br/>
			Yewen Li, Shuai Mao, Jingtong Gao, Nan Jiang, Yunjian Xu, <b>Qingpeng Cai*</b>, Fei Pan, Peng Jiang, Bo An<br/>
			WWW-2025, Industry Track<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
			<b>AURO: Reinforcement Learning for Adaptive User Retention Optimization in Recommender Systems</b><br/>
			Zhenghai Xue, <b>Qingpeng Cai*</b>, Tianyou Zuo, Bin Yang, Lantao Hu, Peng Jiang, Kun Gai, Bo An<br/>
			WWW-2025, Oral <br/>
			</p></li>
		</ul>


			<ul>
		<li><p>
			<b>Value Function Decomposition in Markov Recommendation Process</b><br/>
			Xiaobei Wang, Shuchang Liu, <b>Qingpeng Cai</b>, Xiang Li, Lantao Hu, Han Li, Guangming Xie<br/>
			WWW-2025, Oral <br/>
				</p></li>
		</ul>



		<ul>
		<li><p>
			<b>Modeling User Retention through Generative Flow Networks</b><br/>
			<a href=https://arxiv.org/pdf/2406.06043>[pdf]</a><br/>
			Ziru Liu, Shuchang Liu, Bin Yang, Zhenghai Xue, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Zijian Zhang, Lantao Hu, Han Li, Peng Jiang<br/>
			KDD-2024, industry track<br/>
			</p></li>
		</ul>

		<ul>
		<li><p>
			<b>Future Impact Decomposition in Request-level Recommendations</b><br/>
			<a href=https://arxiv.org/abs/2401.16108>[pdf]</a><br/>
			Xiaobei Wang, Shuchang Liu, Xueliang Wang, <b>Qingpeng Cai*</b>, Lantao Hu, Han Li, Peng Jiang, Guangming Xie<br/>
			KDD-2024, industry track<br/>
			</p></li>
		</ul>
		
		<ul>
		<li><p>
			<b>Sequential Recommendation for Optimizing Both Immediate Feedback and Long-term Retention</b><br/>
			<a href=https://arxiv.org/pdf/2404.03637>[pdf]</a><br/>
			Ziru Liu, Shuchang Liu, Zijian Zhang, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Kesen Zhao, Lantao Hu, Peng Jiang, Kun Gai<br/>
			SIGIR-2024 <br/>
			</p></li>
		</ul>

		
				<ul>
		<li><p>
			<b>M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework</b><br/>
			<a href=https://arxiv.org/pdf/2404.18465>[pdf]</a><br/>
			Zijian Zhang, Shuchang Liu, Jiaao Yu, <b>Qingpeng Cai</b>, Xiangyu Zhao, Chunxu Zhang, Ziru Liu, Qidong Liu, Hongwei Zhao, Lantao Hu, Peng Jiang, Kun Gai<br/>
			SIGIR-2024 <br/>
			</p></li>
		</ul>
		
			<ul>
		<li><p>
			<b>KuaiSim: A Comprehensive Simulator for Recommender Systems</b>
			<a href=https://arxiv.org/abs/2309.12645>[pdf]</a><br/>
			Kesen Zhao, Shuchang Liu,  <b>Qingpeng Cai*</b>, Xiangyu Zhao*, Ziru Liu, Dong Zheng, Peng Jiang, Kun Gai<br/>
			NeurIPS-2023 <br/>
			</p></li>
		</ul>









<ul>
			<li><p>
			<b>ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor</b>
			<a href=https://openreview.net/forum?id=HmPOzJQhbwg>[pdf]</a><br/>
			Wanqi Xue, <b>Qingpeng Cai</b>, Ruohan Zhan, Dong Zheng, Peng Jiang, Kun Gai, Bo An<br/>
			ICLR-2023 <br/>
			</p></li>
		</ul>


				<ul>
			<li><p>
			<b> PrefRec: Recommender Systems with Human Preferences for Reinforcing Long-term User Engagement</b>
			<a href=https://arxiv.org/pdf/2212.02779.pdf>[pdf]</a><br/>
			Wanqi Xue, <b>Qingpeng Cai</b>, Zhenghai Xue, Shuo Sun, Shuchang Liu, Dong Zheng, Peng Jiang, Kun Gai, Bo An<br/>
			KDD-2023<br/>
			</p></li>
		</ul>
		

		<ul>
		<li><p>
			<b>Generative Flow Network for Listwise Recommendation</b>
			<a href=https://arxiv.org/pdf/2306.02239.pdf>[pdf]</a><br/>
			Shuchang Liu, <b>Qingpeng Cai</b>, Zhankui He, Bowen Sun, Julian McAuley, Dong Zheng, Peng Jiang, Kun Gai<br/>
			KDD-2023<br/>
			</p></li>
		</ul>
	</li>
	
			

			
					<ul>
			
			<li><p>
			<b>Multi-Task Recommendations with Reinforcement Learning</b>
			<a href=https://arxiv.org/pdf/2302.03328.pdf>[pdf]</a><br/>
			Ziru Liu, Jiejie Tian, <b>Qingpeng Cai*</b>, Xiangyu Zhao*, Jingtong Gao, Shuchang Liu, Dayou Chen, Tonghao He, Dong Zheng, Peng Jiang and Kun Gai<br/>
			WWW-2023<br/>
			</p></li>
		</ul>


				<ul>
					<li><p>
			<b>Exploration and Regularization of the Latent Action Space in Recommendation</b>
			<a href=https://arxiv.org/pdf/2302.03431.pdf>[pdf]</a><br/>
			Shuchang Liu, <b>Qingpeng Cai</b>, Bowen Sun, Yuhao Wang, Dong Zheng, Peng Jiang, Kun Gai, Ji Jiang, Xiangyu Zhao and Yongfeng Zhang<br/>
			WWW-2023<br/>
			</p></li>
		</ul>


		
		<ul>
			<li><p>
			<b>Two-Stage Constrained Actor-Critic for Short Video Recommendation</b>
			<a href=https://arxiv.org/pdf/2302.01680.pdf>[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Zhenghai Xue, Chi Zhang, Wanqi Xue, Shuchang Liu, Ruohan Zhan, Xueliang Wang, Tianyou Zuo, Wentao Xie, Dong Zheng, Peng Jiang and Kun Gai<br/>
			WWW-2023<br/>
			</p></li>
		</ul>


			<ul>
			<li><p>
			<b>Reinforcing User Retention in a Billion Scale Short Video Recommender System</b>
			<a href=https://arxiv.org/pdf/2302.01724.pdf>[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Shuchang Liu, Xueliang Wang, Tianyou Zuo, Wentao Xie, Bin Yang, Dong Zheng, Peng Jiang and Kun Gai<br/>
			WWW-2023, industry track <br/>
			<a href=https://mp.weixin.qq.com/s/TnxwXnzqrooZl_lapTIB3g>[news link]</a><br/>
			</p></li>
		</ul>

	
		
<li><b>Mechanism Design</b>  <br/>
	
		<ul>
			<li><p>
				<b>Reinforcement Mechanism Design for E-commerce</b> 
				<a href="./pdfs/reinforcement.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang, Yiwei Zhang<br/>
				WWW-2018<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
				<b>Reinforcement Mechanism Design for Fraudulent Behaviour in E-commerce</b> 
				<a href="./pdfs/drl.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang, Yiwei Zhang<br/>
				AAAI-2018<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Ranking Mechanism Design for Price-setting Agents in E-commerce</b> 
			<a href="./pdfs/ranking.pdf">[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Pingzhong Tang, Yulong Zeng<br/>
			AAMAS-2018<br/>
		</ul>
		<ul>
			<li><p>
				<b>Multi-armed Bandit Mechanism With Private Histories</b>
				<a href="./pdfs/AAMAS_2017_paper_108.pdf">[pdf]</a><br/>
				Chang Liu, <b>Qingpeng Cai</b>, Yukui Zhang<br/>
				AAMAS-2017 (Extended abstract)<br/>
			</p></li>
		</ul>
		<ul>
	        <li><p>
				<b>Facility location with Minimax Envy</b>
				<a href=http://iiis.tsinghua.edu.cn/~kenshin/facility.pdf>[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang<br/>
				IJCAI-2016<br/>
			</p></li>
		</ul>

		<ul>
	        <li><p>
				<b>Mechanism Design for Personalized Recommender Systems</b>
				<a href="./pdfs/taobao_recsys.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Chang Liu, Pingzhong Tang<br/>
				Recsys-2016<br/>
			</p></li>
		</ul>
			</li>
		

		<div id="footer">
			<div id="footer-text">
				Page generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
			</div>
		</div>
</body>
	<a href="https://clustrmaps.com/site/1atwx" title="Visit tracker" style="display: block; text-align: center;"><img src="//www.clustrmaps.com/map_v2.png?d=fI6l97ATMnJMe_jCS3Aj1TNv1RDXRjGYsfXrMj71AUY&cl=ffffff"></a>

</html>
