<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
	<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
	<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css" />
	<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet" />

	<title>Qingpeng Cai</title>
</head>

<body>
	<div id="wrap">

		<div id="toptitle">
			<h1>Qingpeng Cai (蔡庆芃)</h1>
		</div>
		<div id="separator"></div>

		<table class="imgtable"><tr><td>
			<img src="photos/qingpengcai.jpeg" alt="" width="180px" height="200px" />&nbsp;</td>
			<td align="left"><p><br /> <br />
			<br />
			</p>
		</td></tr></table>

		<h2>About Me</h2>
		<p>
			I am now a Staff Algorithm Engineer (高级算法专家) in KuaiShou, where I lead the Reinforcement Learning for Recommender System group. I was a Senior Algorithm Engineer (算法专家) in Alibaba Group(Ali Star, 2019).
			I recieved my Ph.D. from Institute for <a href="http://iiis.tsinghua.edu.cn/en/">Institute for Interdisciplinary Information Sciences</a> headed by <a href="https://iiis.tsinghua.edu.cn/yao/">Prof. Andrew Yao</a> (姚期智), <a href="http://www.tsinghua.edu.cn/publish/thu2018en/index.html">Tsinghua University</a>, and I was advised by Prof. Pingzhong Tang.
		Before that, I received my B.S. from <a href="https://www.nju.edu.cn/EN/7f/6b/c7136a163691/page.htm">Department of Computer Science and Technology</a>, <a href="https://www.nju.edu.cn/EN/main.htm">Nanjing University</a>, China. During my undergraduate, I worked in the <a href="http://www.lamda.nju.edu.cn/MainPage.ashx">LAMDA</a> group headed by <a href="https://cs.nju.edu.cn/zhouzh/">Prof. Zhi-Hua Zhou</a>.
		
		
		<h2>Research Interests</h2>
		<p>My research interests include reinforcement learning, and recommender system.</p>
		
		</li>
		</ul>
	
		<h2>Invited Talk</h2>
		<ul>
			
			<li><p>
			<b> Reinforcement Learning for Industrial Recommender Systems</b>
                        <a href="./pdfs/drl4ir.pdf">[pdf]</a><br/>
			DRL4IR@SIGIR2022<br/>
			</p></li>

		</ul>
	
		<h2>Program Services</h2>
		<ul>
			<li>Transactions of Machine Learning Research</li>
			<li>ACM SIGKDD, 2022</li>
			<li>International Joint Conference on Artificial Intelligence (IJCAI), 2021,2022</li>
			<li>Conference on Neural Information Processing Systems (NeurIPS), 2020, 2021, 2022</li>
			<li>International Conference on Learning Representations (ICLR), 2020, 2021, 2022, 2023</li>
			<li>International Conference on Machine Learning (ICML), 2021, 2022</li>
			<li>AAAI Conference on Artificial Intelligence (AAAI), 2020, 2021, 2022</li>
			<li>The Web Conference (WWW), 2021</li>
		</ul>
		</li>
		</ul>

		<h2>Working Papers</h2>
		<ul>
			
			<li><p>
			<b>Constrained Reinforcement Learning for Short Video Recommendation</b>
			<a href=https://arxiv.org/abs/2205.13248>[pdf]</a><br/>
			</p></li>
			
			<li><p>
			<b>ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor</b>
			<a href=https://arxiv.org/abs/2206.02620>[pdf]</a><br/>
			</p></li>
		</ul>

		<h2>Publications</h2>

		</ul>


		<ul>
			<li><p>
			<b>Exploration in policy optimization through multiple paths</b><br/> 
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			JAAMAS <br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
			<b>Softmax Deep Double Deterministic Policy Gradients</b><br/> 
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			NeurIPS-2020 <br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Reinforcement Learning with Dynamic Boltzmann Softmax Updates</b><br/> 
			Ling Pan, <b>Qingpeng Cai</b>, Qi Meng, Wei Chen, Longbo Huang<br/>
			IJCAI-2020, Yokohama, Japan <br/>
			(Acceptance rate: 12.6%)<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Multi-path Policy Optimization</b>
			<a href=https://arxiv.org/abs/1911.04207>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			AAMAS-2020, Auckland, New Zeland <br/>
			<font color="Blue">(Invited for fast-track publication in JAAMAS, top 5%)</font><br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Deterministic Value-Policy Gradients</b>
			<a href=https://arxiv.org/abs/1909.03939>[pdf]</a><br/>
			<b>Qingpeng Cai*</b>, Ling Pan*, Pingzhong Tang (* indicates equal contribution)<br/>
			AAAI-2020, New York, USA<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
				<b>Reinforcement Learning Driven Heuristic Optimization</b>
				<a href=https://arxiv.org/abs/1906.06639>[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Will Hang, Azalia Mirhoseini, George Tucker, Jingtao Wang, Wei Wei<br/>
				DRL4KDD-2019, Alaska, USA <br/>
			</p></li>			
		</ul>

		<ul>
			<li><p>
				<b>A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems</b> 
				<a href=https://arxiv.org/pdf/1802.04592.pdf>[pdf]</a><br/>
				Ling Pan, <b>Qingpeng Cai</b>, Zhixuan Fang, Pingzhong Tang, Longbo Huang<br/>
				AAAI-2019, Hawaii, USA<br/>
			</p></li>
		</ul>
			<ul>
			<li><p>
				<b>Policy optimization with model-based explorations</b><br/>
Feiyang Pan, <b>Qingpeng Cai</b>, An-Xiang Zeng, Chun-Xiang Pan, Qing Da, Hualin He, Qing He, Pingzhong Tang<br/>
				AAAI-2019, Hawaii, USA<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
				<b>Policy gradients for contextual recommendations</b><br/>
				Feiyang Pan, <b>Qingpeng Cai</b>, Pingzhong Tang, Fuzhen Zhuang, Qing He<br/>
				WWW-2019<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
				<b>Reinforcement Mechanism Design for E-commerce</b> 
				<a href="./pdfs/reinforcement.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang, Yiwei Zhang<br/>
				WWW-2018, Lyon, France<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
				<b>Reinforcement Mechanism Design for Fraudulent Behaviour in E-commerce</b> 
				<a href="./pdfs/drl.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang, Yiwei Zhang<br/>
				AAAI-2018, New Orleans, USA<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>Ranking Mechanism Design for Price-setting Agents in E-commerce</b> 
			<a href="./pdfs/ranking.pdf">[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Pingzhong Tang, Yulong Zeng<br/>
			AAMAS-2018, Stockholm, Sweden<br/>
		</ul>
		<ul>
			<li><p>
				<b>Multi-armed Bandit Mechanism With Private Histories</b>
				<a href="./pdfs/AAMAS_2017_paper_108.pdf">[pdf]</a><br/>
				Chang Liu, <b>Qingpeng Cai</b>, Yukui Zhang<br/>
				AAMAS-2017 (Extended abstract), Brazil<br/>
			</p></li>
		</ul>
		<ul>
	        <li><p>
				<b>Facility location with Minimax Envy</b>
				<a href=http://iiis.tsinghua.edu.cn/~kenshin/facility.pdf>[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang<br/>
				IJCAI-2016, NewYork, USA<br/>
			</p></li>
		</ul>
		<ul>
	        <li><p>
				<b>Mechanism Design for Personalized Recommender Systems</b>
				<a href="./pdfs/taobao_recsys.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Chang Liu, Pingzhong Tang<br/>
				ACM Recsys-2016, Boston, USA<br/>
			</p></li>
		</ul>
		

		<div id="footer">
			<div id="footer-text">
				Page generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
			</div>
		</div>
</body>
	<a href="https://clustrmaps.com/site/1atwx" title="Visit tracker" style="display: block; text-align: center;"><img src="//www.clustrmaps.com/map_v2.png?d=fI6l97ATMnJMe_jCS3Aj1TNv1RDXRjGYsfXrMj71AUY&cl=ffffff"></a>

</html>






