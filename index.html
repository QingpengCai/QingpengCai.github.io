<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
	<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
	<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css" />
	<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet" />

	<title>Qingpeng Cai</title>
</head>

<body>
	<div id="wrap">

		<div id="toptitle">
			<h1>Qingpeng Cai (蔡庆芃)</h1>


		</div>
		<div id="separator"></div>

		<table class="imgtable"><tr><td>
			<img src="photos/qingpengcai.png" alt="" width="200px" height="230px" />&nbsp;</td>
			<td align="left"><p><br /> <br />
			<br />
			</p>
		</td></tr></table>


		<p>
Qingpeng Cai is currently a Senior Staff Research Scientist at Kuaishou Technology, where he is responsible for business optimization and technical management. He received his Ph.D. from Institute for Interdisciplinary Information Sciences (IIIS) at Tsinghua University. He received his B.E. from Nanjing University. His core research focuses on Reinforcement Learning and its applications to Large Language Models and practical domains (Recommender Systems and Advertising). He serves as Area Chair for top-tier machine learning conferences including NeurIPS, ICLR. He was awarded the 2024 Qian Weichang Prize for Chinese Information Processing Science and Technology (First Prize in Natural Sciences). Additionally, he led his team to win dual-track championships in the NeurIPS 2024 Auto-Bidding in Large-Scale Auctions Competition.
In 2025, he proposed the Generative Model for RL (G4RL) bidding paradigm, which was fully applied to the advertising system, increasing the platform's revenue by more than 3%. 		More information can be found in <a href=https://scholar.google.com/citations?user=uU6s1tYAAAAJ&hl=en>Google Scholar</a>, <a href=https://dblp.org/pid/183/0940-1.html>DBLP</a>, <a href=https://github.com/ksRecoTech/Kuai-RL/tree/main>Reinforcement Learning works in Kuaishou Technology</a>
<br/><br/>
蔡庆芃目前在快手科技担任算法总监，负责业务优化和技术管理工作。他于清华大学交叉信息研究院获得博士学位，本科毕业于南京大学。他的研究兴趣专注在强化学习以及其在大语言模型以及实际问题（推荐、广告领域）的应用。他担任NeurIPS, ICLR等机器学习顶级会议的领域主席。他曾获得<a href="https://www.cipsc.org.cn/InstituteNews/info_itemid_4753.html">[2024年钱伟长中文信息处理科学技术奖（自然科学一等奖）]</a>，并在NeurIPS 2024自动出价比赛中获得[<a href="https://mp.weixin.qq.com/s/H2hrUEFVEm1uvsIBCNCe7g">双赛道冠军]</a>。
他于2025年提出<a href="https://mp.weixin.qq.com/s/dTHPyEmImRO944BvV3-XAg">[生成式强化学习（Generative Model for RL，G4RL）出价范式]</a>，全面应用在广告系统，平台收入提升超过3%。
			
<br/><br/>


	
	
		<h2>Selected Invited Talks</h2>
		<ul>
			
			<li><p>
			<b> Reinforcement Learning for Short Video Recommender Systems</b>
                        <a href="https://videorecsys.com/slides/qingpeng_talk4.pdf">[pdf]</a><br/>
			The 1st Workshop on
LARGE-SCALE VIDEO RECOMMENDER SYSTEMS@ACM RecSys'23<br/>
			</p></li>


			<li><p>
			<b> Reinforcement Learning for Industrial Recommender Systems</b>
                        <a href="./pdfs/drl4ir.pdf">[pdf]</a><br/>
			DRL4IR@SIGIR2022<br/>
			</p></li>

		</ul>
	
		<h2>Professional Activities</h2>


		<ul>
		<li><b>Organizer:</b> <a href="https://agentirworkshop.github.io/about">Agent-based Information Retrieval Workshop </a>@SIGIR 2024, SIGIR 2025
			</ul>


			<ul>
			<li><b>Area Chair:</b>
			NeurIPS, ICLR
			</ul>

			<ul>
			<li><b>Senior Program Committee:</b>
			AAMAS, CIKM
			</ul>

			<h2>Preprint(* indicates the corresponding author)</h2>


			<ul>
			<li><p>
			<b>1.Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration</b>
			<a href=https://arxiv.org/pdf/2505.17621>[pdf]</a><br/>
				Jingtong Gao, Ling Pan, Yejing Wang, Rui Zhong, Chi Lu,  <b>Qingpeng Cai*</b>, Peng Jiang, Xiangyu Zhao<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
			<b>2.TrackRec: Iterative Alternating Feedback with Chain-of-Thought via Preference Alignment for Recommendation</b>
			<a href=https://arxiv.org/pdf/2508.15388>[pdf]</a><br/>
			Yu Xia, Rui Zhong, Zeyu Song, Wei Yang, Junchen Wan, <b>Qingpeng Cai</b>, Chi Lu, Peng Jiang<br/>
			</p></li>
		</ul>

			<ul>
			<li><p>
			<b>3.Generative Auto-Bidding in Large-Scale Competitive Auctions via Diffusion Completer-Aligner</b>
			<a href=https://arxiv.org/pdf/2509.03348>[pdf]</a><br/>
			Yewen Li, Jingtong Gao, Nan Jiang, Shuai Mao, Ruyi An, Fei Pan, Xiangyu Zhao, Bo An, <b>Qingpeng Cai*</b>, Peng Jiang<br/>
			</p></li>
		</ul>

					<ul>
			<li><p>
			<b>4.Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards</b>
			<a href=https://arxiv.org/pdf/2509.24981>[pdf]</a><br/>
			Haoran He, Yuxiao Ye, <b>Qingpeng Cai</b>, Chen Hu, Binxing Jiao, Daxin Jiang, Ling Pan<br/>
			</p></li>
		</ul>





		<h2>Publications(* indicates the corresponding author)</h2>

						<ul>
			<li><p>
			<b>39. LBM: Hierarchical Large Auto-Bidding Model with Reasoning and Acting</b><br/>
				Yewen Li, Zhiyi Lyu, Peng Jiang, <b>Qingpeng Cai*</b>, Fei Pan, Bo An and Peng Jiang<br/>
			WWW-2026<br/>
			</p></li>
		</ul>

						<ul>
			<li><p>
			<b>38.Hierarchical Semantic RL: Tackling the Problem of Dynamic Action Space for RL-based Recommendations</b>
			<a href=https://arxiv.org/pdf/2510.09167>[pdf]</a><br/>
			Minmao Wang, Xingchen Liu, Shijie Yi, Likang Wu, Hongke Zhao, Fei Pan, <b>Qingpeng Cai*</b>, Peng Jiang<br/>
			WWW-2026<br/>
			</p></li>
		</ul>



				<ul>
			<li><p>
			<b>37.TemporalExpertNet: Cross-Temporal Knowledge Reuse for Promotion-Aware CVR Prediction</b><br/>
				Minmao Wang, Rui Zhang, Shijie Yi, <b>Qingpeng Cai*</b>, Likang Wu, Hongke Zhao, Fei Pan and Peng Jiang<br/>
			WSDM-2026<br/>
			</p></li>
		</ul>

			<ul>
			<li><p>
			<b>36.Random Policy Evaluation Uncovers Policies of Generative Flow Networks</b><br/>
				Haoran He, Emmanuel Bengio, <b>Qingpeng Cai</b>, Ling Pan<br/>
			ICML-2025<br/>
			</p></li>
		</ul>


			<ul>
		<li><p>
			<b>35.LLM-Powered Efficient User Simulator for Recommender System</b>
			<a href=https://arxiv.org/pdf/2412.16984>[pdf]</a><br/>
			Zijian Zhang, Shuchang Liu, Ziru Liu, Rui Zhong, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Chunxu Zhang, Qidong Liu, Peng Jiang<br/>
			AAAI-2025, Oral <br/>
				</p></li>
		</ul>

		<ul>
			<li><p>
			<b>34.Flow Factorization for Efficient Generative Flow Networks</b>
			<a href=https://ojs.aaai.org/index.php/AAAI/article/view/34887>[pdf]</a><br/>
			Jiashun Liu, Chunhui Li, Cheng-Hao Liu, Dianbo Liu, <b>Qingpeng Cai</b>, Ling Pan<br/>
			AAAI-2025, Oral <br/>
			</p></li>
		</ul>

		<ul>
		<li><p>
			<b>33.DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems</b>
			<a href=https://arxiv.org/pdf/2408.12470>[pdf]</a><br/>
			Jiaju Chen, Chongming Gao, Shuai Yuan, Shuchang Liu,  <b>Qingpeng Cai</b>, Peng Jiang<br/>
			WSDM-2025 <br/>
			</p></li>
		</ul>


		
		


		<ul>
			<li><p>
			<b>32.Generative Auto-Bidding with Value-Guided Explorations</b><a href=https://arxiv.org/pdf/2504.14587>[pdf]</a><br/>
			Jingtong Gao, Yewen Li, Shuai Mao, Peng Jiang, Nan Jiang, Yejing Wang,  <b>Qingpeng Cai*</b>, Fei Pan, Peng Jiang, Kun Gai, Bo An, Xiangyu Zhao<br/>
			SIGIR-2025<br/>
			</p></li>
		</ul>





		<ul>
			<li><p>
			<b>31.GAS: Generative Auto-bidding with Post-training Search</b>
			<a href=https://arxiv.org/pdf/2412.17018>[pdf]</a><br/>
			Yewen Li, Shuai Mao, Jingtong Gao, Nan Jiang, Yunjian Xu, <b>Qingpeng Cai*</b>, Fei Pan, Peng Jiang, Bo An<br/>
			WWW-2025, Industry Track<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
			<b>30.AURO: Reinforcement Learning for Adaptive User Retention Optimization in Recommender Systems</b><a href=https://arxiv.org/pdf/2310.03984>[pdf]</a><br/>
			Zhenghai Xue, <b>Qingpeng Cai*</b>, Tianyou Zuo, Bin Yang, Lantao Hu, Peng Jiang, Kun Gai, Bo An<br/>
			WWW-2025, Oral <br/>
			</p></li>
		</ul>




			<ul>
		<li><p>
			<b>29.Value Function Decomposition in Markov Recommendation Process</b><a href=https://arxiv.org/abs/2501.17409>[pdf]</a><br/>
			Xiaobei Wang, Shuchang Liu, <b>Qingpeng Cai</b>, Xiang Li, Lantao Hu, Han Li, Guangming Xie<br/>
			WWW-2025, Oral <br/>
				</p></li>
		</ul>

		


		<ul>
		<li><p>
			<b>28.Modeling User Retention through Generative Flow Networks</b>
			<a href=https://arxiv.org/pdf/2406.06043>[pdf]</a><br/>
			Ziru Liu, Shuchang Liu, Bin Yang, Zhenghai Xue, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Zijian Zhang, Lantao Hu, Han Li, Peng Jiang<br/>
			KDD-2024, industry track<br/>
			</p></li>
		</ul>

		<ul>
		<li><p>
			<b>27.Future Impact Decomposition in Request-level Recommendations</b>
			<a href=https://arxiv.org/abs/2401.16108>[pdf]</a><br/>
			Xiaobei Wang, Shuchang Liu, Xueliang Wang, <b>Qingpeng Cai*</b>, Lantao Hu, Han Li, Peng Jiang, Guangming Xie<br/>
			KDD-2024, industry track<br/>
			</p></li>
		</ul>
		
		<ul>
		<li><p>
			<b>26.Sequential Recommendation for Optimizing Both Immediate Feedback and Long-term Retention</b>
			<a href=https://arxiv.org/pdf/2404.03637>[pdf]</a><br/>
			Ziru Liu, Shuchang Liu, Zijian Zhang, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Kesen Zhao, Lantao Hu, Peng Jiang, Kun Gai<br/>
			SIGIR-2024 <br/>
			</p></li>
		</ul>

		
				<ul>
		<li><p>
			<b>25.M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework</b>
			<a href=https://arxiv.org/pdf/2404.18465>[pdf]</a><br/>
			Zijian Zhang, Shuchang Liu, Jiaao Yu, <b>Qingpeng Cai</b>, Xiangyu Zhao, Chunxu Zhang, Ziru Liu, Qidong Liu, Hongwei Zhao, Lantao Hu, Peng Jiang, Kun Gai<br/>
			SIGIR-2024 <br/>
			</p></li>
		</ul>



							<ul>
		<li><p>
			<b>24.State Regularized Policy Optimization on Data with Dynamics Shift</b>
			<a href=https://arxiv.org/abs/2306.03552>[pdf]</a><br/>
			Zhenghai Xue,  <b>Qingpeng Cai</b>, Shuchang Liu, Dong Zheng, Peng Jiang, Kun Gai, Bo An<br/>
			NeurIPS-2023 <br/>
			</p></li>
		</ul>
		
			<ul>
		<li><p>
			<b>23.KuaiSim: A Comprehensive Simulator for Recommender Systems</b>
			<a href=https://arxiv.org/abs/2309.12645>[pdf]</a><br/>
			Kesen Zhao, Shuchang Liu,  <b>Qingpeng Cai*</b>, Xiangyu Zhao, Ziru Liu, Dong Zheng, Peng Jiang, Kun Gai<br/>
			NeurIPS-2023 <br/>
			</p></li>
		</ul>









<ul>
			<li><p>
			<b>22.ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor</b>
			<a href=https://openreview.net/forum?id=HmPOzJQhbwg>[pdf]</a><br/>
			Wanqi Xue, <b>Qingpeng Cai</b>, Ruohan Zhan, Dong Zheng, Peng Jiang, Kun Gai, Bo An<br/>
			ICLR-2023 <br/>
			</p></li>
		</ul>


				<ul>
			<li><p>
			<b> 21.PrefRec: Recommender Systems with Human Preferences for Reinforcing Long-term User Engagement</b>
			<a href=https://arxiv.org/pdf/2212.02779.pdf>[pdf]</a><br/>
			Wanqi Xue, <b>Qingpeng Cai</b>, Zhenghai Xue, Shuo Sun, Shuchang Liu, Dong Zheng, Peng Jiang, Kun Gai, Bo An<br/>
			KDD-2023<br/>
			</p></li>
		</ul>
		

		<ul>
		<li><p>
			<b>20.Generative Flow Network for Listwise Recommendation</b>
			<a href=https://arxiv.org/pdf/2306.02239.pdf>[pdf]</a><br/>
			Shuchang Liu, <b>Qingpeng Cai</b>, Zhankui He, Bowen Sun, Julian McAuley, Dong Zheng, Peng Jiang, Kun Gai<br/>
			KDD-2023<br/>
			</p></li>
		</ul>
	</li>
	
			

			
					<ul>
			
			<li><p>
			<b>19.Multi-Task Recommendations with Reinforcement Learning</b>
			<a href=https://arxiv.org/pdf/2302.03328.pdf>[pdf]</a><br/>
			Ziru Liu, Jiejie Tian, <b>Qingpeng Cai*</b>, Xiangyu Zhao, Jingtong Gao, Shuchang Liu, Dayou Chen, Tonghao He, Dong Zheng, Peng Jiang and Kun Gai<br/>
			WWW-2023<br/>
			</p></li>
		</ul>


				<ul>
					<li><p>
			<b>18.Exploration and Regularization of the Latent Action Space in Recommendation</b>
			<a href=https://arxiv.org/pdf/2302.03431.pdf>[pdf]</a><br/>
			Shuchang Liu, <b>Qingpeng Cai</b>, Bowen Sun, Yuhao Wang, Dong Zheng, Peng Jiang, Kun Gai, Ji Jiang, Xiangyu Zhao and Yongfeng Zhang<br/>
			WWW-2023<br/>
			</p></li>
		</ul>


		
		<ul>
			<li><p>
			<b>17.Two-Stage Constrained Actor-Critic for Short Video Recommendation</b>
			<a href=https://arxiv.org/pdf/2302.01680.pdf>[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Zhenghai Xue, Chi Zhang, Wanqi Xue, Shuchang Liu, Ruohan Zhan, Xueliang Wang, Tianyou Zuo, Wentao Xie, Dong Zheng, Peng Jiang and Kun Gai<br/>
			WWW-2023<br/>
			</p></li>
		</ul>


			<ul>
			<li><p>
			<b>16.Reinforcing User Retention in a Billion Scale Short Video Recommender System</b>
			<a href=https://arxiv.org/pdf/2302.01724.pdf>[pdf]</a>			<br/>
			<b>Qingpeng Cai</b>, Shuchang Liu, Xueliang Wang, Tianyou Zuo, Wentao Xie, Bin Yang, Dong Zheng, Peng Jiang and Kun Gai<br/>
			WWW-2023, industry track <br/>

			</p></li>
		</ul>

	


		<ul>
			<li><p>
			<b>15.Exploration in policy optimization through multiple paths</b><br/> 
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			JAAMAS-2021<br/>
			</p></li>
		</ul>


				<ul>
			<li><p>
			<b>14.Softmax Deep Double Deterministic Policy Gradients</b>
			<a href=https://proceedings.neurips.cc/paper/2020/file/884d247c6f65a96a7da4d1105d584ddd-Paper.pdf>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			NeurIPS-2020 <br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>13.Reinforcement Learning with Dynamic Boltzmann Softmax Updates</b>
			<a href=https://www.ijcai.org/proceedings/2020/0276.pdf>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Qi Meng, Wei Chen, Longbo Huang<br/>
			IJCAI-2020<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>12.Multi-path Policy Optimization</b>
			<a href=https://arxiv.org/abs/1911.04207>[pdf]</a><br/>
			Ling Pan, <b>Qingpeng Cai</b>, Longbo Huang<br/>
			AAMAS-2020<br/>
			<font color="Blue">(Invited for fast-track publication in JAAMAS, top 5%)</font><br/>
			</p></li>
		</ul>

		<ul>
			
			<li><p>
			<b>11.Deterministic Value-Policy Gradients</b>
			<a href=https://arxiv.org/abs/1909.03939>[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Ling Pan, Pingzhong Tang<br/>
			AAAI-2020<br/>
			</p></li>
		</ul>



					<ul>
			<li><p>
				<b>10.Policy optimization with model-based explorations</b><br/>
Feiyang Pan, <b>Qingpeng Cai</b>, An-Xiang Zeng, Chun-Xiang Pan, Qing Da, Hualin He, Qing He, Pingzhong Tang<br/>
				AAAI-2019<br/>
			</p></li>
		</ul>

					<ul>
			<li><p>
				<b>9.A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems</b> 
				<a href=https://arxiv.org/pdf/1802.04592.pdf>[pdf]</a><br/>
				Ling Pan, <b>Qingpeng Cai</b>, Zhixuan Fang, Pingzhong Tang, Longbo Huang<br/>
				AAAI-2019<br/>
			</p></li>
		</ul>

		<ul>
			<li><p>
				<b>8.Reinforcement Learning Driven Heuristic Optimization</b>
				<a href=https://arxiv.org/abs/1906.06639>[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Will Hang, Azalia Mirhoseini, George Tucker, Jingtao Wang, Wei Wei<br/>
				DRL4KDD-2019<br/>
			</p></li>			
		</ul>





		<ul>
			<li><p>
				<b>7.Policy gradients for contextual recommendations</b><br/>
				Feiyang Pan, <b>Qingpeng Cai</b>, Pingzhong Tang, Fuzhen Zhuang, Qing He<br/>
				WWW-2019<br/>
			</p></li>
		</ul>

</li>

		

	
		<ul>
			<li><p>
				<b>6.Reinforcement Mechanism Design for E-commerce</b> 
				<a href="./pdfs/reinforcement.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang, Yiwei Zhang<br/>
				WWW-2018<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
				<b>5.Reinforcement Mechanism Design for Fraudulent Behaviour in E-commerce</b> 
				<a href="./pdfs/drl.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang, Yiwei Zhang<br/>
				AAAI-2018<br/>
			</p></li>
		</ul>
		<ul>
			<li><p>
			<b>4.Ranking Mechanism Design for Price-setting Agents in E-commerce</b> 
			<a href="./pdfs/ranking.pdf">[pdf]</a><br/>
			<b>Qingpeng Cai</b>, Pingzhong Tang, Yulong Zeng<br/>
			AAMAS-2018<br/>
		</ul>
		<ul>
			<li><p>
				<b>3.Multi-armed Bandit Mechanism With Private Histories</b>
				<a href="./pdfs/AAMAS_2017_paper_108.pdf">[pdf]</a><br/>
				Chang Liu, <b>Qingpeng Cai</b>, Yukui Zhang<br/>
				AAMAS-2017 (Extended abstract)<br/>
			</p></li>
		</ul>
		<ul>
	        <li><p>
				<b>2.Facility location with Minimax Envy</b>
				<a href=http://iiis.tsinghua.edu.cn/~kenshin/facility.pdf>[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Pingzhong Tang<br/>
				IJCAI-2016<br/>
			</p></li>
		</ul>

		<ul>
	        <li><p>
				<b>1.Mechanism Design for Personalized Recommender Systems</b>
				<a href="./pdfs/taobao_recsys.pdf">[pdf]</a><br/>
				<b>Qingpeng Cai</b>, Aris Filos-Ratsikas, Chang Liu, Pingzhong Tang<br/>
				Recsys-2016<br/>
			</p></li>
		</ul>
			</li>
		

		<div id="footer">
			<div id="footer-text">
				Page generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
			</div>
		</div>
</body>
	<a href="https://clustrmaps.com/site/1atwx" title="Visit tracker" style="display: block; text-align: center;"><img src="//www.clustrmaps.com/map_v2.png?d=fI6l97ATMnJMe_jCS3Aj1TNv1RDXRjGYsfXrMj71AUY&cl=ffffff"></a>

</html>
